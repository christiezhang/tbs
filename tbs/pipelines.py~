#-*- coding: UTF-8 -*-
# __author__ = 'christie'
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html
from twisted.enterprise import adbapi
from scrapy.http import Request
from scrapy.exceptions import DropItem
import time,hashlib
import MySQLdb
import MySQLdb.cursors
import sys
reload(sys)
sys.setdefaultencoding('utf-8')
from tbs.pmemcache import pmemcache
class tbsPipeline(object):

    res=['?','+','.','#','^','*','{','}',',','(',')','<','>','...','!','|','\'']

    def __init__(self):
        self.dbpool = adbapi.ConnectionPool('MySQLdb',db='tbs1',user='root',passwd='',cursorclass=MySQLdb.cursors.DictCursor,charset='utf8',use_unicode=False)
        #self.timestamp = str(int(time.mktime(time.gmtime())))
        self.dbip = '127.0.0.1'
        self.dbname='tbs1'
        self.memcache = pmemcache()
    def process_item(self, item, spider):
        #if spider.name =='singlecrawl':
              #query = self.dbpool.runInteraction(self.singlecrawl_conditional_insert, item)
        #elif spider.name == 'discoveryspider':
              #query = self.dbpool.runInteraction(self.discoveryspider_conditional_insert, item)
        if spider.name == 'tbs1':
              query = self.dbpool.runInteraction(self.tbs1_pipeline,item)
        #print item['stripedbody']
        return item
    def escape_str(self,v):     #not run at here,run@pipelines
            if type(v) is not str:
                return False
                #return False
            returnstr=''
            for x in v:
                if x in self.res:
                    returnstr = returnstr+'\\'+x if len(returnstr)>0 else '\\'+x
                else:
                     returnstr = returnstr+x if len(returnstr)>0 else x
            return returnstr
    def tbs1_pipeline(self,tx,item):
        try:
            tx.execute('insert into `page_information`(`id`,`url`,`character`,`spiderid`,`urlsetid`,`dbip`,`crawldate`,\
                       `lastmodify`,`expired`,`refer`,`crawlstats`,`searchkeywords`,`dbname`,`title`,`keywords`,`description`,\
                       `html`,`textcontent`) values (NULL,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)',(str(item.get('url','')),\
                        str(item.get('character','')),str(item.get('spiderid','')),str(item.get('urlsetid','')),str(self.dbip),\
                        str(int(time.mktime(time.gmtime()))),str(item.get('LastModified','')),str(item.get('Expires','')),\
                        str(item.get('refer','')),str(item.get('crawl_stats','')),self.escape_str(str(item.get('searchkeywords',''))),str(self.dbname),self.escape_str(str(item.get('title',''))),\
                        self.escape_str(str(item.get('keyword',''))),self.escape_str(str(item.get('desc',''))),self.escape_str(str(item.get('body',''))),self.escape_str(str(item.get('stripedbody','')))))
            insertid = tx.connection.insert_id()      #if need
            livetime = self.memcache.Memcache_default_live if int(item.get('Expires',0)) <= int(time.mktime(time.gmtime())) else int(item.get('Expires',0))-int(time.mktime(time.gmtime()))
            self.memcache.set(str(item.get('url_hash_no_fragment','')),self.memcache.Memcache_default_value,livetime)
        except Exception as dberror:
            tx.execute('insert into page_error_log (id,url,log,date)values(\' \',%s,%s,%s)',(str(item.get('url','')),self.escapt_str(str(dberror)),str(int(time.mktime(time.gmtime())))))
            return
