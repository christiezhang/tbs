#-*- coding: UTF-8 -*-
#__author__='christie'
import sys,time,hashlib,os,re,chardet,datetime,time
reload(sys)
sys.setdefaultencoding('utf-8')
import MySQLdb
from scrapy.spider import BaseSpider
from scrapy.selector import HtmlXPathSelector
from scrapy.http import Request
from urlparse import urlparse
from urlparse import urljoin
from urlparse import urlunparse
from posixpath import normpath
#from HTMLParser import HTMLParser
from BeautifulSoup import BeautifulSoup,Tag,NavigableString,Comment
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from urllib import urlretrieve
from urlparse import urlsplit
#from scrapy.item import Item
from tbs.items import TbsItem              # import self declared items

class tbs1(BaseSpider):
    name = 'tbs1'
    defult_strip_start_tag = 'body'
    striptag=['scripts','script','style']
    default_encoding_confidence=0.9
    max_page=100

    def __init__(self):
        self.start_urls=[]
        #self.keyword = keyword
        self.keyword = '菜籽油 市场'
        #for x in range(self.max_page):
            #self.start_urls.append('http://www.baidu.com/s?wd=%E8%8F%9C%E7%B1%BD%E6%B2%B9+%E5%B8%82%E5%9C%BA&pn='+str(int(10*x)))
            #self.start_urls.append('http://www.baidu.com/s?wd='+self.keyword+'&pn='+str(int(10*x)))
        self.start_urls=['http://www.baidu.com/link?url=dKMJjfWCXQ5r-rCphMnG_cWhl8ToOh_obRzxXDgQ7hNbB5yMlUzNBt2LDQ5Rt4LHOic72RB1OIZh-lz_bb_flq']
        self.allowed_domains=[]

    def parse(self,response):
       print response.body
       return
       links =[]
       try:
              linkextracts =  SgmlLinkExtractor(allow='^http://www\.baidu\.com/link\?.*',allow_domains=self.allowed_domains).extract_links(response)
       except:
              return
       for link in linkextracts:
              links.append(link.url)
       #links.append(response.url) if response.url not in links else links
       for l in links:
            print l
            yield Request(l,callback=self.parse_detail,errback=self.parse_error)

    def parse_detail(self,response):
          item = TbsItem()
          headers = response.headers
          hashobject = hashlib.md5()
          hashobject.update(self.parseurl(response.url))
          self.set_items_value(item,'url_hash_no_fragment', hashobject.hexdigest())
          self.set_items_value(item,'url', response.url)
          self.set_items_value(item,'root_domain',urlparse(response.url).hostname)
          self.set_items_value(item,'Expires',self.to_GMT_timestamp(headers['Expires']) if 'Expires' in headers.keys() else self.to_GMT_timestamp(None))
          self.set_items_value(item,'LastModified',self.to_GMT_timestamp(headers['Last-Modified']) if 'Last-Modified' in headers.keys() else self.to_GMT_timestamp(None))
          try:
               hxs = HtmlXPathSelector(response)
               self.set_items_value(item,'title',','.join(hxs.select('//title/text()').extract()))
               self.set_items_value(item,'desc',','.join(hxs.select('//meta[@name="description"]/@content').extract()))
               self.set_items_value(item,'keyword',','.join(hxs.select('//meta[@name="keywords"]/@content').extract()))
          except:
               self.set_items_value(item,'title',' ')
               self.set_items_value(item,'desc',' ')
               self.set_items_value(item,'keyword',' ')
          self.set_items_value(item,'stripedbody',self.strip_html_tags1(response.body))
          print self.strip_html_tags1(response.body)


    def strip_html_tags1(self,html,soupobject=None):
           characterinfo = chardet.detect(html)
           character = characterinfo['encoding'] if characterinfo['confidence']>=self.default_encoding_confidence and characterinfo else 'utf8'
           html=html.decode(character,'ignore').encode('utf8')
           soupobject = BeautifulSoup(html) if soupobject is None else soupobject
           htmlbody = getattr(soupobject,self.defult_strip_start_tag)
           try:
                comments = htmlbody.findAll(text=lambda text:isinstance(text,Comment))  #get rid of html comment
           except AttributeError:
               return False
           [comment.extract() for comment in comments]
           rv=''
           for x in htmlbody:
               if isinstance(x,NavigableString) and x !='\n':
                   rv = x if rv=='' else rv+' '+str(x)
               elif isinstance(x,Tag) and x.name not in self.striptag:
                   rv = self.strip_html_tags1(x) if rv=='' else rv+' '+str(self.html_tag_iterator(x))
           return rv
    def set_items_value(self,itemobject,key,value):
           try:
               itemobject[key]=value
           except KeyError:
               itemobject[key]=''
           return itemobject

    def to_GMT_timestamp(self,date):
           if date is None:
               return str(int(time.mktime(time.gmtime())))
           datefomat = '%a, %d %b %Y %H:%M:%S %Z'
           try:
               d = datetime.datetime.strptime(date,datefomat)
               return str(int(time.mktime(d.timetuple())))
           except Exception:
               return str(int(time.mktime(time.gmtime())))


    def parse_error(self,response):
           return response


    def parseurl(self,url):
           try:
               ob = urlparse(url)
               return urlunparse((ob.scheme, ob.netloc, ob.path,ob.params, ob.query,'')) #take away url fragment
           except Exception:
               return url



